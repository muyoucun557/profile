# 分库分表的实践

``场景``
在洋葱工作的期间，我们实现了【老师布置作业，学生写作业】这样的功能。其中有一张表记录了每一道习题的完成情况，由于记录的是每个学生每次作业中每道习题的完成情况，因此这张表的数量是巨大的。
如果老师布置了10次作业，每次作业20道习题，每个班级有30名学生，那么该表就有10*20*30=6000条记录。
在业务规则上，老师和学生看不到半年前的作业，我们为了减少表数据量，每天定时迁移无用数据。即使是这样，这张表最高的时候达到了4亿条数据。

数据库使用的是PG，在高峰时期数据库的负载很大。

## 分析以及解决方案

单实例负载过高，必然要增加实例来分担请求压力。数据库的压力来自于两种：读压力和写压力。
在我们这个场景中，应该是要分担读压力还是分担写压力，还是要读写压力都要分担？

如果仅仅是要分担读压力，可以使用读写分离的方案来解决。
如果要分担写压力，那么就需要分库来解决。

不记得当时高峰时期写操作的tps是多少了，咨询过阿里云的技术，他们给出的回复是，写压力挺大的，那么采用分库的方案来解决。

为什么还采用分表呢？

在做了数据迁移的情况下，数据量最高达到了4亿条，分成两个数据库之后，单表达到2亿条，这数据量太大，影响性能。

最终选择分库分表方案来解决这个问题。

2个数据库实例，每个实例的4张表。最高的时候每张表5000w张。

## 实施过程中的问题以及处理方案

### 问题一：按照哪个字段进行sharding

老师布置作业的时候，针对每一次作业，都会有一张作业表记录：记录哪个老师在什么时候针对那些班级布置了作业。
使用作业表的id作为sharding字段。

### 问题二：表的id怎么处理，防重复

使用的是雪花算法生成的id。golang里时钟具有单调增属性，无需担心时钟回拨的问题

### 问题三：原数据怎么做迁移

原数据是存储在一张表中，现在需要分到不同的表中，因此需要做迁移。有什么方案能平滑迁移吗？
没想到有什么好的方案能做到平滑迁移的。
是凌晨的时候做了数据迁移。

如果采用时间作为sharding的键，那么就不需要有硬迁移数据的情况。但是采用时间作为sharding键的话，不能起到分担读写压力的作用。

### 


